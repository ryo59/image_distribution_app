Optimizer: Adam | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 3.343197914759318 | Test Accuracy: 0.6366666674613952
Optimizer: Adam | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 3.267779544194539 | Test Accuracy: 0.5200000003973643
Optimizer: Adam | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 5.406289656596879 | Test Accuracy: 0.33666666666666667
Optimizer: Adam | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 2.5806940746307374 | Test Accuracy: 0.55
Optimizer: Adam | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 6.113466826677322 | Test Accuracy: 0.40666666676600777
Optimizer: Adam | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 3.3180501810709635 | Test Accuracy: 0.506666667064031
Optimizer: Adam | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 3.1949432563781737 | Test Accuracy: 0.6266666666666667
Optimizer: Adam | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 1.099459301630656 | Test Accuracy: 0.3333333333333333
Optimizer: Adam | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 3.167272243499756 | Test Accuracy: 0.6733333325386047
Optimizer: Adam | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 3.131421038309733 | Test Accuracy: 0.6899999992052714
Optimizer: Adam | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 4.189144512812296 | Test Accuracy: 0.6299999992052714
Optimizer: Adam | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 2.8850033569335936 | Test Accuracy: 0.6666666658719381
Optimizer: Adam | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 4.344640817642212 | Test Accuracy: 0.6633333333333333
Optimizer: Adam | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 2.3710112794240317 | Test Accuracy: 0.7
Optimizer: Adam | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 3.5172927316029865 | Test Accuracy: 0.7066666666666667
Optimizer: Adam | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 2.1594924100240074 | Test Accuracy: 0.7133333333333334
Optimizer: SGD | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 1.6090786933898926 | Test Accuracy: 0.6566666666666666
Optimizer: SGD | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 1.1016047970453897 | Test Accuracy: 0.3333333333333333
Optimizer: SGD | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 2.0061881653467815 | Test Accuracy: 0.6433333341280619
Optimizer: SGD | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 1.098841848373413 | Test Accuracy: 0.3333333333333333
Optimizer: SGD | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 1.7222426700592042 | Test Accuracy: 0.6833333333333333
Optimizer: SGD | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 1.0986600923538208 | Test Accuracy: 0.3333333333333333
Optimizer: SGD | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 2.198680559794108 | Test Accuracy: 0.6599999992052714
Optimizer: SGD | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 1.0986250829696655 | Test Accuracy: 0.3333333333333333
Optimizer: SGD | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 1.248784700234731 | Test Accuracy: 0.7266666658719381
Optimizer: SGD | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 3.172612009048462 | Test Accuracy: 0.6233333341280619
Optimizer: SGD | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 1.5672440616289776 | Test Accuracy: 0.6933333325386047
Optimizer: SGD | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 2.9494363594055177 | Test Accuracy: 0.6566666666666666
Optimizer: SGD | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 1.9652475754419962 | Test Accuracy: 0.7033333325386047
Optimizer: SGD | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 2.413420325915019 | Test Accuracy: 0.6433333341280619
Optimizer: SGD | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 2.341619147459666 | Test Accuracy: 0.6833333325386047
Optimizer: SGD | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 2.1385937563578286 | Test Accuracy: 0.6266666674613952
Optimizer: SGDM | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 2.0956742509206134 | Test Accuracy: 0.6566666658719381
Optimizer: SGDM | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 1.0988232374191285 | Test Accuracy: 0.3333333333333333
Optimizer: SGDM | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 1.9952221457163493 | Test Accuracy: 0.683333334128062
Optimizer: SGDM | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 1.0987326574325562 | Test Accuracy: 0.3333333333333333
Optimizer: SGDM | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 2.0369124889373778 | Test Accuracy: 0.6866666666666666
Optimizer: SGDM | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 1.0989013783137003 | Test Accuracy: 0.3333333333333333
Optimizer: SGDM | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 2.1651573467254637 | Test Accuracy: 0.7166666658719381
Optimizer: SGDM | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 1.0987013737360636 | Test Accuracy: 0.3333333333333333
Optimizer: SGDM | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 2.9632491874694824 | Test Accuracy: 0.6366666666666667
Optimizer: SGDM | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 3.69552170753479 | Test Accuracy: 0.6133333333333333
Optimizer: SGDM | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 3.3924969021479288 | Test Accuracy: 0.6366666658719381
Optimizer: SGDM | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 3.423025229771932 | Test Accuracy: 0.6466666658719381
Optimizer: SGDM | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 4.010539828936259 | Test Accuracy: 0.6199999992052714
Optimizer: SGDM | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 2.7410202995936075 | Test Accuracy: 0.6333333325386047
Optimizer: SGDM | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 3.222604382832845 | Test Accuracy: 0.6166666666666667
Optimizer: SGDM | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 2.5539816363652545 | Test Accuracy: 0.6399999992052714
Optimizer: RMSprop | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 3.5517796834309894 | Test Accuracy: 0.6766666674613953
Optimizer: RMSprop | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 1.1028389763832092 | Test Accuracy: 0.3333333333333333
Optimizer: RMSprop | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 5.491838864882787 | Test Accuracy: 0.5666666662693024
Optimizer: RMSprop | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 1.0986167653401693 | Test Accuracy: 0.3333333333333333
Optimizer: RMSprop | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 4.142028338114421 | Test Accuracy: 0.6499999992052714
Optimizer: RMSprop | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 1.1051595306396484 | Test Accuracy: 0.3333333333333333
Optimizer: RMSprop | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 5.9734054506411 | Test Accuracy: 0.5266666666666666
Optimizer: RMSprop | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 1.1099983978271484 | Test Accuracy: 0.3333333333333333
Optimizer: RMSprop | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 3.619741668701172 | Test Accuracy: 0.72
Optimizer: RMSprop | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 5.539950100580851 | Test Accuracy: 0.6533333325386047
Optimizer: RMSprop | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 4.430892966588338 | Test Accuracy: 0.6666666666666666
Optimizer: RMSprop | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 5.387344258626302 | Test Accuracy: 0.6566666666666666
Optimizer: RMSprop | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 4.15218022664388 | Test Accuracy: 0.6699999992052714
Optimizer: RMSprop | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 4.767515449523926 | Test Accuracy: 0.7033333325386047
Optimizer: RMSprop | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 3.8314652919769285 | Test Accuracy: 0.7033333325386047
Optimizer: RMSprop | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 4.791173375447591 | Test Accuracy: 0.6966666666666667
Optimizer: Adagrad | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 1.3426757049560547 | Test Accuracy: 0.68
Optimizer: Adagrad | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 5.8357675480842595 | Test Accuracy: 0.3333333333333333
Optimizer: Adagrad | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 1.4787781174977621 | Test Accuracy: 0.686666665871938
Optimizer: Adagrad | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 5.834867540200551 | Test Accuracy: 0.3333333333333333
Optimizer: Adagrad | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 1.3514563926060994 | Test Accuracy: 0.7199999992052714
Optimizer: Adagrad | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 1.0986711486180623 | Test Accuracy: 0.3333333333333333
Optimizer: Adagrad | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 1.3441848643620808 | Test Accuracy: 0.7099999992052713
Optimizer: Adagrad | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 1.101832939783732 | Test Accuracy: 0.3333333333333333
Optimizer: Adagrad | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 3.7409988689422606 | Test Accuracy: 0.62
Optimizer: Adagrad | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 10.745396962165833 | Test Accuracy: 0.3333333333333333
Optimizer: Adagrad | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 3.1263478914896647 | Test Accuracy: 0.6533333325386047
Optimizer: Adagrad | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 10.745396970113118 | Test Accuracy: 0.3333333333333333
Optimizer: Adagrad | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 3.9289282528559366 | Test Accuracy: 0.6266666658719381
Optimizer: Adagrad | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 10.74539695739746 | Test Accuracy: 0.3333333333333333
Optimizer: Adagrad | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 2.6361979611714683 | Test Accuracy: 0.6799999992052714
Optimizer: Adagrad | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 2.4613669967651366 | Test Accuracy: 0.7133333341280619
Optimizer: Adadelta | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 2.696703936258952 | Test Accuracy: 0.6733333325386047
Optimizer: Adadelta | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 3.3519866943359373 | Test Accuracy: 0.5099999996026358
Optimizer: Adadelta | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 3.2117616589864095 | Test Accuracy: 0.6666666658719381
Optimizer: Adadelta | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 1.0986317841211954 | Test Accuracy: 0.3333333333333333
Optimizer: Adadelta | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 2.5618689473470053 | Test Accuracy: 0.703333334128062
Optimizer: Adadelta | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 1.0986256424585978 | Test Accuracy: 0.3333333333333333
Optimizer: Adadelta | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 1.9803277850151062 | Test Accuracy: 0.73
Optimizer: Adadelta | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 1.0986207962036132 | Test Accuracy: 0.3333333333333333
Optimizer: Adadelta | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 3.1672816324234008 | Test Accuracy: 0.6800000007947286
Optimizer: Adadelta | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 3.958349806467692 | Test Accuracy: 0.6533333325386047
Optimizer: Adadelta | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 2.7842266082763674 | Test Accuracy: 0.7100000007947286
Optimizer: Adadelta | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 3.5664843114217124 | Test Accuracy: 0.686666665871938
Optimizer: Adadelta | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 3.022853266398112 | Test Accuracy: 0.7099999992052713
Optimizer: Adadelta | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 3.6795972029368085 | Test Accuracy: 0.6733333325386047
Optimizer: Adadelta | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 2.787938453356425 | Test Accuracy: 0.706666665871938
Optimizer: Adadelta | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 3.4816022364298504 | Test Accuracy: 0.7166666658719381
Optimizer: Adamax | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 4.903868144353231 | Test Accuracy: 0.566666667064031
Optimizer: Adamax | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 5.835535726547241 | Test Accuracy: 0.3333333333333333
Optimizer: Adamax | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 2.9870315043131512 | Test Accuracy: 0.6666666674613952
Optimizer: Adamax | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 1.105645430882772 | Test Accuracy: 0.3333333333333333
Optimizer: Adamax | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 2.219282134373983 | Test Accuracy: 0.6799999992052714
Optimizer: Adamax | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 1.0989058430989582 | Test Accuracy: 0.3333333333333333
Optimizer: Adamax | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 1.9468992527325948 | Test Accuracy: 0.7133333325386048
Optimizer: Adamax | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 1.0989504194259643 | Test Accuracy: 0.3333333333333333
Optimizer: Adamax | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 3.5247954909006753 | Test Accuracy: 0.6700000007947285
Optimizer: Adamax | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 3.3293189732233683 | Test Accuracy: 0.6933333325386047
Optimizer: Adamax | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 3.1547454961140953 | Test Accuracy: 0.6833333325386047
Optimizer: Adamax | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 3.261149247487386 | Test Accuracy: 0.6833333325386047
Optimizer: Adamax | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 3.006138728459676 | Test Accuracy: 0.6833333333333333
Optimizer: Adamax | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 2.7943533023198444 | Test Accuracy: 0.7133333325386048
Optimizer: Adamax | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 2.6012916660308836 | Test Accuracy: 0.7099999992052713
Optimizer: Adamax | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 2.377098873456319 | Test Accuracy: 0.72
Optimizer: Nadam | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 1.8578252045313517 | Test Accuracy: 0.6266666658719381
Optimizer: Nadam | Activation: sigmoid | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 1.108913722038269 | Test Accuracy: 0.3333333333333333
Optimizer: Nadam | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 3.1836020723978677 | Test Accuracy: 0.5666666667660077
Optimizer: Nadam | Activation: sigmoid | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 1.0989276313781737 | Test Accuracy: 0.3333333333333333
Optimizer: Nadam | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 3.134209953943888 | Test Accuracy: 0.6099999992052714
Optimizer: Nadam | Activation: sigmoid | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 1.1188527409235636 | Test Accuracy: 0.3333333333333333
Optimizer: Nadam | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 1.8572915840148925 | Test Accuracy: 0.676666667064031
Optimizer: Nadam | Activation: sigmoid | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 1.6773896900812786 | Test Accuracy: 0.5666666666666667
Optimizer: Nadam | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: True | Test Loss: 4.973814194997152 | Test Accuracy: 0.6366666658719381
Optimizer: Nadam | Activation: relu | Dropout_rate: 0.01 | Batch Normalization: False | Test Loss: 10.745396962165833 | Test Accuracy: 0.3333333333333333
Optimizer: Nadam | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: True | Test Loss: 4.2519055970509845 | Test Accuracy: 0.6633333333333333
Optimizer: Nadam | Activation: relu | Dropout_rate: 0.1 | Batch Normalization: False | Test Loss: 10.745396970113118 | Test Accuracy: 0.3333333333333333
Optimizer: Nadam | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: True | Test Loss: 4.880255800882975 | Test Accuracy: 0.6333333341280619
Optimizer: Nadam | Activation: relu | Dropout_rate: 0.25 | Batch Normalization: False | Test Loss: 5.177626546223959 | Test Accuracy: 0.6166666674613953
Optimizer: Nadam | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: True | Test Loss: 3.727486956914266 | Test Accuracy: 0.706666665871938
Optimizer: Nadam | Activation: relu | Dropout_rate: 0.5 | Batch Normalization: False | Test Loss: 2.7416067282358805 | Test Accuracy: 0.69

---Best parameter---
Optimizer: Adadelta 
Activation: sigmoid 
Dropout_rate 0.5 
Batch Normalization: True 
Test Loss: 1.9803277850151062 
Test Accuracy: 0.73